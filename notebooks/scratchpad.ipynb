{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import src\n",
    "import numpy as np\n",
    "import k3d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from ipywidgets import interact, widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cube = np.load('../data/raw/train_labels.npy')\n",
    "cube = cube[15:cube.shape[0]-16, 15:cube.shape[1]-16, 15:cube.shape[2]-16]\n",
    "cubek3d = cube + 1\n",
    "plot = k3d.plot()\n",
    "(w, h, d) = cubek3d.shape\n",
    "obj = k3d.voxels(np.swapaxes(np.swapaxes(cubek3d, 0, 2), 0, 1), bounds=[0,w, 0,d,0,h], opacity=0.3, outlines=False)\n",
    "plot += obj\n",
    "plot.camera=[150, 230, -40, 60, 85, 80, 0.0, 0.0, -1.0]\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_indexes(cube, sample_size):\n",
    "    shape = cube.shape\n",
    "\n",
    "    indexes = [\n",
    "        (iline, xline, depth)\n",
    "        for iline in range(shape[0] - sample_size + 1)\n",
    "        for xline in range(shape[1] - sample_size + 1)\n",
    "        for depth in range(shape[2] - sample_size + 1)\n",
    "    ]\n",
    "\n",
    "    return indexes\n",
    "\n",
    "cube = np.arange(3*3*3).reshape(3,3,3)\n",
    "indexes = pred_indexes(cube, 2)\n",
    "print(len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from livelossplot.keras import PlotLossesCallback\n",
    "from src.sequences import F3Sequence\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def split_indexes(cube, sample_size):\n",
    "    shape = cube.shape\n",
    "\n",
    "    indexes = [\n",
    "        (iline, xline, depth)\n",
    "        for iline in range(shape[0] - sample_size)\n",
    "        for xline in range(shape[1] - sample_size)\n",
    "        for depth in range(shape[2] - sample_size)\n",
    "    ]\n",
    "    \n",
    "    train_indexes, val_indexes = train_test_split(indexes, test_size=0.2, shuffle=True)\n",
    "    return train_indexes, val_indexes\n",
    "\n",
    "seismic_cube = np.load('../data/raw/train_seismic.npy')\n",
    "facies_cube = np.load('../data/raw/train_labels.npy')\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(facies_cube), facies_cube.flatten())\n",
    "\n",
    "batch_size = 500\n",
    "sample_size = 32\n",
    "input_shape = (sample_size, sample_size, 3)\n",
    "n_classes = len(np.unique(facies_cube))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (7, 7), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(\n",
    "    lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "train_indexes, val_indexes = split_indexes(seismic_cube, sample_size)\n",
    "\n",
    "training_sequence = F3Sequence(seismic_cube, facies_cube, train_indexes, batch_size, sample_size)\n",
    "validation_sequence = F3Sequence(seismic_cube, facies_cube, val_indexes, batch_size, sample_size)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=training_sequence,\n",
    "    validation_data=validation_sequence,\n",
    "    use_multiprocessing=False,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights,\n",
    "    workers=4,\n",
    "    verbose=1,\n",
    "    callbacks=[PlotLossesCallback(), keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/trained_model_f3_32_full.h5')\n",
    "print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/interim/f3_32.h5'\n",
    "with h5py.File(filename, 'r') as dataset:\n",
    "    x_train_original = np.array(dataset['train/X'])\n",
    "    y_train_original = np.array(dataset['train/Y'])\n",
    "    \n",
    "m = x_train_original.shape[0]\n",
    "\n",
    "classnames = {\n",
    "    0: 'Upper North',\n",
    "    1: 'Middle North',\n",
    "    2: 'Lower North',\n",
    "    3: 'Chalk/Rijnland',\n",
    "    4: 'Scruff',\n",
    "    5: 'Zechstein',\n",
    "}    \n",
    "\n",
    "print(f'Training examples: {m}')\n",
    "print(f'Example shape: {x_train_original[0].shape}')\n",
    "\n",
    "train_freq = src.class_frequency(y_train_original, len(classnames))\n",
    "src.plot_classes_freq(train_freq, classnames.values(), title='Training classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 5\n",
    "idx = np.random.choice(m, nrows * ncols)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "for i in range(1, nrows * ncols +1):\n",
    "    fig.add_subplot(nrows, ncols, i)\n",
    "    plt.imshow(x_train_original[idx[i-1]])\n",
    "    plt.title(f'class: {classnames[y_train_original[idx[i-1]][0]]}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = np.load('../models/f3-train-pred.npy')  \n",
    "predk3d = pred + 1\n",
    "(w, h, d) = pred.shape\n",
    "plot = k3d.plot()\n",
    "obj = k3d.voxels(np.swapaxes(np.swapaxes(predk3d, 0, 2), 0, 1), bounds=[0,w, 0,d,0,h], opacity=0.5, outlines=False)\n",
    "plot += obj\n",
    "plot.camera=[150, 230, -40, 60, 85, 80, 0.0, 0.0, -1.0]\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_section(z=0):\n",
    "    fig, axes = plt.subplots(1, 2, dpi=250)\n",
    "    axes[0].imshow(cube[:,:,z], vmin=0, vmax=5)\n",
    "    axes[1].imshow(pred[:,:,z], vmin=0, vmax=5)\n",
    "\n",
    "interact(plot_section, z=widgets.IntSlider(min=0,max=pred.shape[2] - 1,step=1,value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...\\n')\n",
    "\n",
    "y_true = cube.flatten()\n",
    "y_pred = pred.flatten()\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_borders(cube, image_size):\n",
    "    shape = cube.shape\n",
    "    half = int(image_size / 2)\n",
    "    return cube[(half - 1):shape[0] - half, (half - 1):shape[1] - half, (half - 1):shape[2] - half]\n",
    "\n",
    "def mean_class_accuracy(cm):\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "    \n",
    "    class_acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return np.mean(class_acc)\n",
    "    \n",
    "def evaluate(y_true, y_pred):    \n",
    "    print('Evaluating model...\\n')\n",
    "\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    accuracy = mean_class_accuracy(matrix)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    \n",
    "    matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    return {\n",
    "        'mean-accuracy': accuracy,\n",
    "        'precision-macro': precision,\n",
    "        'recall-macro': recall,\n",
    "        'f1-score-macro': f1,\n",
    "        'confusion-matrix': matrix,\n",
    "    }\n",
    "\n",
    "def show_results(results):\n",
    "    print(f'Mean-accuracy:    \\t{results[\"mean-accuracy\"]}')\n",
    "    print(f'Precision(macro): \\t{results[\"precision-macro\"]}')\n",
    "    print(f'Recall(macro):    \\t{results[\"recall-macro\"]}')\n",
    "    print(f'F1-Score(macro): \\t{results[\"f1-score-macro\"]}')\n",
    "\n",
    "    src.plot_confusion_matrix(results[\"confusion-matrix\"], classnames.values(), title=\"Confusion matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "true1_name = 'test1_labels.npy'\n",
    "true2_name = 'test2_labels.npy'\n",
    "\n",
    "cube_pred1_name = 'pred-f3_test1-64-fulldata.npy'\n",
    "cube_pred2_name = 'pred-f3_test2-64-fulldata.npy'\n",
    "\n",
    "cube_true1 = np.load(f'../data/raw/{true1_name}')\n",
    "cube_true1 = remove_borders(cube_true1, image_size)\n",
    "cube_true2 = np.load(f'../data/raw/{true2_name}')\n",
    "cube_true2 = remove_borders(cube_true2, image_size)\n",
    "\n",
    "cube_pred1 = np.load(f'../models/{cube_pred1_name}')\n",
    "cube_pred2 = np.load(f'../models/{cube_pred2_name}')\n",
    "\n",
    "y_true1 = cube_true1.flatten()\n",
    "y_pred1 = cube_pred1.flatten()\n",
    "\n",
    "y_true2 = cube_true2.flatten()\n",
    "y_pred2 = cube_pred2.flatten()\n",
    "\n",
    "# print('Test #1')\n",
    "# results = evaluate(y_true1, y_pred1)\n",
    "# show_results(results)\n",
    "# print('\\n')\n",
    "\n",
    "# print('Test #2')\n",
    "# results = evaluate(y_true2, y_pred2)\n",
    "# show_results(results)\n",
    "# print('\\n')\n",
    "\n",
    "print('Test both')\n",
    "results = evaluate(np.concatenate((y_true1, y_true2)), np.concatenate((y_pred1, y_pred2)))\n",
    "# show_results(results)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_true = np.load('../data/raw/test1_labels.npy')\n",
    "test1_true = test1_true[15:test1_true.shape[0]-16, 15:test1_true.shape[1]-16, 15:test1_true.shape[2]-16]\n",
    "test1_pred = np.load('../models/f3-test1-fullmodel-pred.npy')\n",
    "\n",
    "def plot_section(z=0):\n",
    "    fig, axes = plt.subplots(1, 2, dpi=250)\n",
    "    axes[0].imshow(test1_true[z, :, :].T, vmin=0, vmax=5)\n",
    "    axes[1].imshow(test1_pred[z, :, :].T, vmin=0, vmax=5)\n",
    "\n",
    "interact(plot_section, z=widgets.IntSlider(min=0,max=test1_pred.shape[0] - 1,step=1,value=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...\\n')\n",
    "\n",
    "y_true = test1_true.flatten()\n",
    "y_pred = test1_pred.flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred, normalize=True)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Accuracy: \\t{accuracy}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_true = np.load('../data/raw/test2_labels.npy')\n",
    "test2_true = test2_true[15:test2_true.shape[0]-16, 15:test2_true.shape[1]-16, 15:test2_true.shape[2]-16]\n",
    "test2_pred = np.load('../models/f3-test2-fullmodel-pred.npy')\n",
    "\n",
    "print(test2_true.shape)\n",
    "\n",
    "def plot_section(z=0):\n",
    "    fig, axes = plt.subplots(1, 2, dpi=250)\n",
    "    axes[0].imshow(test2_true[z, :, :].T, vmin=0, vmax=5)\n",
    "    axes[1].imshow(test2_pred[z, :, :].T, vmin=0, vmax=5)\n",
    "\n",
    "interact(plot_section, z=widgets.IntSlider(min=0,max=test2_pred.shape[0] - 1,step=1,value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...\\n')\n",
    "\n",
    "y_true = test2_true.flatten()\n",
    "y_pred = test2_pred.flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred, normalize=True)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Accuracy: \\t{accuracy}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "\n",
    "b = np.array([5, 5, 5])\n",
    "\n",
    "def foo(a, b):\n",
    "    return sum(a)/sum(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
