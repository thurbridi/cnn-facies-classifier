{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_eyW-Jkcycv"
   },
   "source": [
    "# CNN for seismic facies classification\n",
    "\n",
    "## Imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1557342212229,
     "user": {
      "displayName": "Arthur Bridi Guazzelli",
      "photoUrl": "https://lh3.googleusercontent.com/-Xe9HGd33jgU/AAAAAAAAAAI/AAAAAAAABuc/PNZWTXxVoCk/s64/photo.jpg",
      "userId": "08648124829811374117"
     },
     "user_tz": 180
    },
    "id": "dly1rq_7az3E",
    "outputId": "5285d6d0-3269-44c8-8861-7789e977f1d3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import k3d\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../data/interim/stanford6_truncated_rgb.h5', 'r') as dataset:\n",
    "    x_train_original = np.array(dataset['train/X'])\n",
    "    y_train_original = np.array(dataset['train/Y'])\n",
    "    x_test_original = np.array(dataset['test/X'])\n",
    "    y_test_original = np.array(dataset['test/Y'])\n",
    "\n",
    "classnames = {\n",
    "    0: 'Floodplain',\n",
    "    1: 'Pointbar',\n",
    "    2: 'Channel',\n",
    "    3: 'Boundary',\n",
    "}    \n",
    "    \n",
    "m = x_train_original.shape[0]\n",
    "num_classes = 4\n",
    "\n",
    "frequencies = src.class_frequency(y_train_original, num_classes)\n",
    "print(f'Training class frequencies: {frequencies}')\n",
    "print(f'Test class frequencies: {src.class_frequency(y_test_original, num_classes)}')\n",
    "\n",
    "nrows, ncols = 2, 5\n",
    "idx = np.random.choice(m, nrows * ncols)\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "for i in range(1, nrows * ncols +1):\n",
    "    fig.add_subplot(nrows, ncols, i)\n",
    "    plt.imshow(x_train_original[idx[i-1]])\n",
    "    plt.title(f'class: {classnames[y_train_original[idx[i-1]][0]]}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MsUFp5GpXn_"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "x_train_resampled, y_train_resampled = ADASYN().fit_resample(np.reshape(x_train_original, (m, np.product(x_train_original.shape[1:]))), y_train_original)\n",
    "x_train_resampled = np.reshape(x_train_resampled, (x_train_resampled.shape[0], *x_train_original.shape[1:]))\n",
    "print(src.class_frequency(y_train_resampled, num_classes))\n",
    "\n",
    "x_train = x_train_resampled / 255\n",
    "y_train = keras.utils.to_categorical(y_train_resampled, num_classes)\n",
    "x_test = x_test_original / 255\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_original / 255\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes)\n",
    "x_test = x_test_original / 255\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1557339285784,
     "user": {
      "displayName": "Arthur Bridi Guazzelli",
      "photoUrl": "https://lh3.googleusercontent.com/-Xe9HGd33jgU/AAAAAAAAAAI/AAAAAAAABuc/PNZWTXxVoCk/s64/photo.jpg",
      "userId": "08648124829811374117"
     },
     "user_tz": 180
    },
    "id": "7rhq9_H6pt6W",
    "outputId": "1fa77ab3-b70c-414a-afcb-53c37d79643b"
   },
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1557342098159,
     "user": {
      "displayName": "Arthur Bridi Guazzelli",
      "photoUrl": "https://lh3.googleusercontent.com/-Xe9HGd33jgU/AAAAAAAAAAI/AAAAAAAABuc/PNZWTXxVoCk/s64/photo.jpg",
      "userId": "08648124829811374117"
     },
     "user_tz": 180
    },
    "id": "fsQq9ezFp7aW",
    "outputId": "50bb4036-6ce5-49e4-e63c-8476266abc41"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 180\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    callbacks=[PlotLossesCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1557342111925,
     "user": {
      "displayName": "Arthur Bridi Guazzelli",
      "photoUrl": "https://lh3.googleusercontent.com/-Xe9HGd33jgU/AAAAAAAAAAI/AAAAAAAABuc/PNZWTXxVoCk/s64/photo.jpg",
      "userId": "08648124829811374117"
     },
     "user_tz": 180
    },
    "id": "lfyBYWPHsEvf",
    "outputId": "ef23ac83-b708-4bdf-df62-9edf072aab0c"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Test {model.metrics_names[i]}: {score}')\n",
    "    \n",
    "predict_class = np.argmax(model.predict(x_test), axis=1)\n",
    "print(f'F1-score: {f1_score(y_test_original, predict_class, average=\"weighted\")}')\n",
    "matrix = confusion_matrix(y_test_original, predict_class)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "      \n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_section(z=0):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(y_test_original.reshape(119, 169, 88)[:,:,z].T)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(predict_class.reshape(119, 169, 88)[:,:,z].T)\n",
    "    \n",
    "interact(plot_section, z=widgets.IntSlider(min=0,max=87,step=1,value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = (0x3A528B, 0x20908C, 0xFDE724)\n",
    "\n",
    "plot = k3d.plot()\n",
    "obj = k3d.voxels(predict_class.reshape(119, 169, 88).T, color_map, compression_level=1)\n",
    "plot += obj\n",
    "plot.display()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_facies_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
